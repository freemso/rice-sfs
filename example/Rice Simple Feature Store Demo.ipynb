{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "094cba45",
   "metadata": {},
   "source": [
    "# Rice Simple Feature Store Demo\n",
    "\n",
    "This is a demo for the rice-sfs system. In this notebook, we would see how to use the system to manage the features. Specifically, we would ingest some features into the system and retrieve them later. Through this process, you will see the workflow of a typical user of the system.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24646d3b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This section help you setup the environment needed in order to run the notebook.\n",
    "\n",
    "We perform all the computation and storing in you local machine.\n",
    "\n",
    "### Local DynamoDB\n",
    "\n",
    "You have to have a local version of DynamoDB server running on your machine.\n",
    "\n",
    "To run a DynamoDB locally, first go\n",
    "to [AWS DynamoDB Developer Guide](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.DownloadingAndRunning.html)\n",
    ", download the archive, and put the extracted `DynamoDBLocal.jar` and `DynamoDBLocal_lib/`\n",
    "in `dynamodb/` directory.\n",
    "\n",
    "Then run:\n",
    "\n",
    "```shell\n",
    "bash dynamodb/start_dynamo_local.sh\n",
    "```\n",
    "\n",
    "Use aws-cli to access DynamoDB:\n",
    "\n",
    "```shell\n",
    "aws dynamodb --endpoint-url http://localhost:8000 <command> [args]\n",
    "```\n",
    "\n",
    "### Local PostgreSQL Server\n",
    "\n",
    "You have to have a local version of PostgreSQL server running on your machine.\n",
    "\n",
    "You can download a PostgreSQL for your OS [here](https://www.postgresql.org/download/) and start the server in the backgroud.\n",
    "\n",
    "By default the PostgreSQL server would run on `localhost:5432`.\n",
    "\n",
    "After getting PostgreSQL running, you should create a user and a database:\n",
    "\n",
    "```shell\n",
    "# create user \"rice\"\n",
    "createuser --createdb rice\n",
    "\n",
    "# create database \"sfs\"\n",
    "createdb --username rice --no-password sfs\n",
    "```\n",
    "\n",
    "We would use the user `rice` to access the database `sfs`.\n",
    "\n",
    "### Local Spark\n",
    "\n",
    "You have to have a local Spark cluster running on your machine.\n",
    "\n",
    "You can find instructions on intalling and deploying a Spark on your local machine [here](https://spark.apache.org/docs/latest/).\n",
    "\n",
    "After getting spark running in the background, you can use `spark-shell` to start a Scala shell:\n",
    "\n",
    "```bash\n",
    "spark-shell --packages io.delta:delta-core_2.12:1.1.0 --conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" --conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "```\n",
    "\n",
    "Note that we add Delta package so that later we can directly query delta lake.\n",
    "\n",
    "### Download Dataset\n",
    "\n",
    "We use the MovieLens 100K Dataset. You can download it [here[(https://grouplens.org/datasets/movielens/100k/).\n",
    "\n",
    "After you download the dataset, please put the extracted `ml-100k/` in `example/data/` directory.\n",
    "\n",
    "### Start the services\n",
    "\n",
    "Go to the root directory of the project. Run `mvn clean package` to package the program.\n",
    "\n",
    "Go the `sfs-registry/` directory. Run `mvn spring-boot:run` to start the feature registry service. By default it will listen to port `8081`.\n",
    "\n",
    "Start another terminal, go to the `sfs-serving/` directory. Run `mvn spring-boot:run` to start the feature serving service. By default it will listen to port `8082`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0683450",
   "metadata": {},
   "source": [
    "## Feature Registry\n",
    "\n",
    "We first register some features in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee91d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_endpoint = \"http://localhost:8081/api/v1\"\n",
    "serving_endpoint = \"http://localhost:8082/api/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5872660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the user entity\n",
    "requests.post(registry_endpoint + \"/entities\", json={\"name\":\"user\",\"description\":\"user in the system\"}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a24cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register some features\n",
    "requests.post(registry_endpoint + \"/features\",\n",
    "              json={\"name\":\"user_age\",\"description\":\"user age\",\"valueType\":\"INT\",\"deltaTableColName\":\"age\",\"dynamoTableColName\":\"age\"}).json()\n",
    "requests.post(registry_endpoint + \"/features\",\n",
    "              json={\"name\":\"user_gender\",\"description\":\"user gender\",\"valueType\":\"STRING\",\"deltaTableColName\":\"gender\",\"dynamoTableColName\":\"gender\"}).json()\n",
    "requests.post(registry_endpoint + \"/features\",\n",
    "              json={\"name\":\"user_occupation\",\"description\":\"user occupation\",\"valueType\":\"STRING\",\"deltaTableColName\":\"occupation\",\"dynamoTableColName\":\"occupation\"}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register a feature table\n",
    "path = os.getcwd()\n",
    "pj_root = os.path.join(path, os.pardir)\n",
    "delta_root = os.path.join(pj_root, \"delta/\")\n",
    "body = {\n",
    "    \"name\":\"user_feat\",\n",
    "    \"description\":\"user feature\",\n",
    "    \"entity\":\"user\",\n",
    "    \"features\":[\"user_age\",\"user_gender\"],\n",
    "    \"dynamoTableName\":\"user_feat\",\n",
    "    \"deltaTablePath\":os.path.abspath(os.path.join(delta_root, \"user_feat/\"))\n",
    "}\n",
    "requests.post(registry_endpoint + \"/featureTables\", json=body).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa4ce4",
   "metadata": {},
   "source": [
    "## Feature Ingestion\n",
    "\n",
    "We would ingest some user features stored in the `ml-100k/u.user` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3042329",
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-submit \\\n",
    "  --master \"local[4]\" \\\n",
    "  --deploy-mode client \\\n",
    "  --class edu.rice.sfs.ingest.BatchIngestApp \\\n",
    "  --name BatchIngestApp \\\n",
    "  --packages com.audienceproject:spark-dynamodb_2.12:1.1.2 \\\n",
    "  --packages io.delta:delta-core_2.12:1.1.0 \\\n",
    "  --conf \"spark.driver.extraJavaOptions=-Daws.dynamodb.endpoint=http://localhost:8000/\" \\\n",
    "  --conf \"spark.sfs.source.batch.options=delimiter:|\" \\\n",
    "  --conf \"spark.sfs.source.batch.format=csv\" \\\n",
    "  --conf \"spark.sfs.source.batch.path=$(pwd)/data/ml-100k/u.user\" \\\n",
    "  --conf \"spark.sfs.source.batch.cols=id, age, gender, occupation, zip_code\" \\\n",
    "  --conf \"spark.sfs.source.batch.feature-table=user_feat\" \\\n",
    "  --conf \"spark.sfs.source.batch.entity-col=id\" \\\n",
    "  --conf \"spark.sfs.source.batch.feature-col-map=user_age:age,user_gender:gender\" \\\n",
    "  --driver-java-options \"-Daws.dynamodb.endpoint=http://localhost:8000/\" \\\n",
    "  --driver-memory 1024M \\\n",
    "  --driver-cores 1 \\\n",
    "  --executor-memory 1G \\\n",
    "  $(dirname `pwd`)/sfs-ingest/target/sfs-ingest-0.0.1-SNAPSHOT-jar-with-dependencies.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e31b6e7",
   "metadata": {},
   "source": [
    "Now you can use spark-shell to see if the feature is actually ingested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794124b6",
   "metadata": {},
   "source": [
    "## Feature Serving\n",
    "\n",
    "We now query the serving service to get the online feature from DynamoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdc334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first register a feature table view.\n",
    "body = {\n",
    "    \"name\":\"user_feat_view\",\n",
    "    \"featureTableName\":\"user_feat\",\n",
    "    \"featureNames\":[\"user_age\"] # only care about the ages\n",
    "}\n",
    "requests.post(registry_endpoint + \"/featureTableViews\", json=body).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(serving_endpoint + \"/getFeature\", params={\"featureTableView\": \"user_feat_view\", \"entity\": \"42\"}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e96641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we care more features, we can use a different view\n",
    "body = {\n",
    "    \"name\":\"user_feat_view_2\",\n",
    "    \"featureTableName\":\"user_feat\",\n",
    "    \"featureNames\":[\"user_age\", \"user_gender\"] # only care about the ages\n",
    "}\n",
    "requests.post(registry_endpoint + \"/featureTableViews\", json=body).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(serving_endpoint + \"/getFeature\", params={\"featureTableView\": \"user_feat_view_2\", \"entity\": \"42\"}).json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
